Improving Linear Regression Using Power Transformer

ğŸ“– Overview

This project focuses on improving Linear Regression performance by handling skewed data using PowerTransformer (Yeo-Johnson).
We analyze the data distribution, apply preprocessing, and compare model performance before and after transformation.

ğŸ“Š Dataset

Name: California Housing Dataset

Source: Scikit-learn

Rows: 20,640

Columns: 9

Target Variable: MedHouseVal

ğŸ›  Tools & Libraries

Python

Pandas, NumPy

Matplotlib, Seaborn

Scikit-learn

âš™ï¸ Steps Followed

1ï¸âƒ£ Load the dataset
2ï¸âƒ£ Select numeric features
3ï¸âƒ£ Replace zero values with 0.001
4ï¸âƒ£ Check skewness of data
5ï¸âƒ£ Split into train and test sets
6ï¸âƒ£ Apply Linear Regression (Before Transformation)
7ï¸âƒ£ Evaluate using RÂ² and RMSE
8ï¸âƒ£ Apply PowerTransformer (Yeo-Johnson)
9ï¸âƒ£ Train model again
ğŸ”Ÿ Re-evaluate and compare results

ğŸ“ˆ Results
Model	RÂ² Score	RMSE
Before PowerTransformer	0.57	0.74
After PowerTransformer	0.60	0.71

âœ” Skewness was reduced
âœ” Model performance improved
âœ” Data became more normally distributed

ğŸ§  Conclusion

The dataset was highly right-skewed before preprocessing.
After applying PowerTransformer, most features became approximately normally distributed.
This helped Linear Regression perform better, increasing RÂ² and reducing error.

Power transformation is useful when data is highly skewed.
